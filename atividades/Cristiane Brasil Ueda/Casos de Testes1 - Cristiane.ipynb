{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9c69fc",
   "metadata": {},
   "source": [
    "### Aluna: Cristiane Brasil Ueda "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5db740",
   "metadata": {},
   "source": [
    "## Função de Rosenbrock \n",
    "\n",
    "A função de Rosenbrock para um vetor de $n$ variáveis é definida como:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = \\sum_{i=1}^{n-1} \\left[100(x_{i+1} - x_i^2)^2 + (1 - x_i)^2\\right]\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $\\mathbf{x} = [x_1, x_2, \\ldots, x_n]$ é o vetor de variáveis.\n",
    "- O somatório vai de $i = 1$ até $n-1$, pois cada termo depende de dois elementos consecutivos do vetor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495dd75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Rosenbrock Results ====\n",
      "\n",
      "Method               |        f(x*) |   nfev |   njev |   nhev |  Time (ms) |  Success\n",
      "--------------------------------------------------------------------------------------\n",
      "Nelder-Mead          |   6.6175e-05 |    243 |    N/A |    N/A |       9.59 |     True\n",
      "BFGS                 |   4.0131e-13 |     30 |     30 |    N/A |       4.00 |     True\n",
      "Newton-CG            |   1.3408e-02 |   1006 |   1006 |   1000 |     144.97 |    False\n",
      "trust-ncg            |   3.3223e-04 |   1001 |    848 |    847 |     121.90 |    False\n",
      "trust-krylov         |   2.7387e-09 |    569 |    569 |    561 |     417.00 |     True\n",
      "trust-exact          |   8.2289e-10 |    655 |    645 |    655 |     306.62 |     True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Combined Rosenbrock function\n",
    "def rosenbrock(x):\n",
    "    fval = sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n",
    "\n",
    "    xm = x[1:-1]\n",
    "    xm_m1 = x[:-2]\n",
    "    xm_p1 = x[2:]\n",
    "    grad = np.zeros_like(x)\n",
    "    grad[1:-1] = 200 * (xm - xm_m1**2) - 400 * (xm_p1 - xm**2) * xm - 2 * (1 - xm)\n",
    "    grad[0] = -400 * x[0] * (x[1] - x[0]**2) - 2 * (1 - x[0])\n",
    "    grad[-1] = 200 * (x[-1] - x[-2]**2)\n",
    "\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        if i > 0:\n",
    "            H[i, i - 1] = -400 * x[i - 1]\n",
    "        if i < n - 1:\n",
    "            H[i, i] = 1200 * x[i]**2 - 400 * x[i + 1] + 2\n",
    "            H[i, i + 1] = -400 * x[i]\n",
    "        else:\n",
    "            H[i, i] = 200\n",
    "    for i in range(n - 1):\n",
    "        H[i + 1, i] = H[i, i + 1]\n",
    "\n",
    "    return fval, grad, H\n",
    "\n",
    "# Initial point\n",
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "\n",
    "# List of methods to compare\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\", \"jac\": lambda x: rosenbrock(x)[1]},\n",
    "    \"Newton-CG\": {\"method\": \"Newton-CG\", \"jac\": lambda x: rosenbrock(x)[1], \"hess\": lambda x: rosenbrock(x)[2]},\n",
    "    \"trust-ncg\": {\"method\": \"trust-ncg\", \"jac\": lambda x: rosenbrock(x)[1], \"hess\": lambda x: rosenbrock(x)[2]},\n",
    "    \"trust-krylov\": {\"method\": \"trust-krylov\", \"jac\": lambda x: rosenbrock(x)[1], \"hess\": lambda x: rosenbrock(x)[2]},\n",
    "    \"trust-exact\": {\"method\": \"trust-exact\", \"jac\": lambda x: rosenbrock(x)[1], \"hess\": lambda x: rosenbrock(x)[2]},\n",
    "}\n",
    "\n",
    "# Executa as otimizações e armazena resultados\n",
    "results = {}\n",
    "\n",
    "for name, opts in methods.items():\n",
    "    start_time = time.time()\n",
    "    res = minimize(lambda x: rosenbrock(x)[0], x0, **opts, options={\"disp\": False})\n",
    "    elapsed_time = (time.time() - start_time) * 1000  # em ms\n",
    "    results[name] = {\n",
    "        \"x0\": x0,\n",
    "        \"x*\": res.x,\n",
    "        \"fval\": res.fun,\n",
    "        \"nfev\": res.nfev,\n",
    "        \"njev\": res.get(\"njev\", None),\n",
    "        \"nhev\": res.get(\"nhev\", None),\n",
    "        \"time\": elapsed_time,\n",
    "        \"success\": res.success\n",
    "    }\n",
    "\n",
    "# Apresenta os resultados com alinhamento\n",
    "print(\"\\n==== Rosenbrock Results ====\\n\")\n",
    "header = f\"{'Method':<20} | {'f(x*)':>12} | {'nfev':>6} | {'njev':>6} | {'nhev':>6} | {'Time (ms)':>10} | {'Success':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for method, data in results.items():\n",
    "    print(f\"{method:<20} | {data['fval']:12.4e} | {data['nfev']:6d} | \"\n",
    "          f\"{data['njev'] if data['njev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['nhev'] if data['nhev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['time']:10.2f} | {str(data['success']):>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8d5e6",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min_{x_1, x_2} \\Bigl(\\cos x_1 ,\\sin x_2 ;-; \\frac{x_1}{x_2^2 + 1}\\Bigr) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfab6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Example 02 Results ====\n",
      "\n",
      "Method               |        f(x*) |   nfev |   njev |   nhev |  Time (ms) |  Success\n",
      "--------------------------------------------------------------------------------------\n",
      "Nelder-Mead          |  -1.0457e+00 |    167 |    N/A |    N/A |      19.88 |     True\n",
      "BFGS                 |  -9.6673e+22 |    248 |    236 |    N/A |      39.83 |    False\n",
      "Newton-CG            |   0.0000e+00 |      1 |      1 |      1 |       4.18 |     True\n",
      "trust-ncg            |  -1.6960e+05 |    399 |    396 |    395 |      40.51 |    False\n",
      "trust-krylov         |   0.0000e+00 |      2 |      2 |      1 |       4.08 |    False\n",
      "trust-exact          |  -2.2003e+05 |    401 |    389 |    401 |     106.46 |    False\n"
     ]
    }
   ],
   "source": [
    "def ex02(x):\n",
    "    x1, x2 = x\n",
    "\n",
    "    # Função\n",
    "    f = np.cos(x1) * np.sin(x2) - x1 / (x2**2 + 1)\n",
    "\n",
    "    # Gradiente\n",
    "    df_dx1 = -np.sin(x1) * np.sin(x2) - 1 / (x2**2 + 1)\n",
    "    df_dx2 = np.cos(x1) * np.cos(x2) + (2 * x1 * x2) / (x2**2 + 1)**2\n",
    "    g = np.array([df_dx1, df_dx2])\n",
    "\n",
    "    # Hessiana\n",
    "    d2f_dx1dx1 = -np.cos(x1) * np.sin(x2)\n",
    "    d2f_dx1dx2 = -np.sin(x1) * np.cos(x2) + (2 * x2) / (x2**2 + 1)**2\n",
    "    d2f_dx2dx1 = d2f_dx1dx2\n",
    "    d2f_dx2dx2 = -np.cos(x1) * np.sin(x2) + \\\n",
    "                 (2 * x1 * (x2**2 + 1)**2 - 8 * x1 * x2**2 * (x2**2 + 1)) / (x2**2 + 1)**4\n",
    "    H = np.array([\n",
    "        [d2f_dx1dx1, d2f_dx1dx2],\n",
    "        [d2f_dx2dx1, d2f_dx2dx2]\n",
    "    ])\n",
    "\n",
    "    return f, g, H\n",
    "\n",
    "# Initial point\n",
    "x0 = np.array([0.0, 0.0])\n",
    "\n",
    "# List of methods to compare\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\", \"jac\": lambda x: ex02(x)[1]},\n",
    "    \"Newton-CG\": {\"method\": \"Newton-CG\", \"jac\": lambda x: ex02(x)[1], \"hess\": lambda x: ex02(x)[2]},\n",
    "    \"trust-ncg\": {\"method\": \"trust-ncg\", \"jac\": lambda x: ex02(x)[1], \"hess\": lambda x: ex02(x)[2]},\n",
    "    \"trust-krylov\": {\"method\": \"trust-krylov\", \"jac\": lambda x: ex02(x)[1], \"hess\": lambda x: ex02(x)[2]},\n",
    "    \"trust-exact\": {\"method\": \"trust-exact\", \"jac\": lambda x: ex02(x)[1], \"hess\": lambda x: ex02(x)[2]},\n",
    "}\n",
    "\n",
    "# Executa as otimizações e armazena resultados\n",
    "results = {}\n",
    "\n",
    "for name, opts in methods.items():\n",
    "    start_time = time.time()\n",
    "    res = minimize(lambda x: ex02(x)[0], x0, **opts, options={\"disp\": False})\n",
    "    elapsed_time = (time.time() - start_time) * 1000  # em ms\n",
    "    results[name] = {\n",
    "        \"x0\": x0,\n",
    "        \"x*\": res.x,\n",
    "        \"fval\": res.fun,\n",
    "        \"nfev\": res.nfev,\n",
    "        \"njev\": res.get(\"njev\", None),\n",
    "        \"nhev\": res.get(\"nhev\", None),\n",
    "        \"time\": elapsed_time,\n",
    "        \"success\": res.success\n",
    "    }\n",
    "\n",
    "# Apresenta os resultados com alinhamento\n",
    "print(\"\\n==== Example 02 Results ====\\n\")\n",
    "header = f\"{'Method':<20} | {'f(x*)':>12} | {'nfev':>6} | {'njev':>6} | {'nhev':>6} | {'Time (ms)':>10} | {'Success':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for method, data in results.items():\n",
    "    print(f\"{method:<20} | {data['fval']:12.4e} | {data['nfev']:6d} | \"\n",
    "          f\"{data['njev'] if data['njev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['nhev'] if data['nhev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['time']:10.2f} | {str(data['success']):>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e0341-072b-468a-b5bb-84fafe35788f",
   "metadata": {},
   "source": [
    "Problem Statistics: \n",
    "\n",
    "\\# of continuous variables: 2\n",
    "\n",
    "\\# of known solutions: 3\n",
    "\n",
    "Global solution:\n",
    "\n",
    "Objective function: -2.02181\n",
    "\n",
    "Continuous variables: $x_1 = 2; x_2 = 0.10578$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae892ca2-c379-4e57-839d-2605d4c1290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': array([0., 0.]),\n",
       " 'x*': array([2.20032125e+05, 6.37081271e-04]),\n",
       " 'fval': np.float64(-220032.03547900406),\n",
       " 'nfev': 401,\n",
       " 'njev': 389,\n",
       " 'nhev': 401,\n",
       " 'time': 106.45842552185059,\n",
       " 'success': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['trust-exact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178c6ccc-2033-4735-a51a-f8f8e8cd61fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-2.0218067833370204),\n",
       " array([-1.08494061e+00, -1.31240428e-05]),\n",
       " array([[ 0.04393797, -0.69731109],\n",
       "        [-0.69731109,  3.78275021]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex02(np.array([2., 0.10578]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59c6b6-00c1-41dd-9e13-ff3fa77cfadf",
   "metadata": {},
   "source": [
    "Testes de derivadas por diferenças finitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75ae822-1cb5-46c0-9e9c-550746518067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.76445575e-09, 1.14897460e-08]),\n",
       " array([[2.34168240e-12, 5.61722197e-12],\n",
       "        [5.61722197e-12, 5.45773426e-11]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradiente e Hessiana numéricas\n",
    "from scipy.optimize import approx_fprime\n",
    "def numerical_hessian(f_grad, x, h=1e-5):\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "    fx = f_grad(x)\n",
    "    for i in range(n):\n",
    "        x1 = x.copy()\n",
    "        x1[i] += h\n",
    "        f1 = f_grad(x1)\n",
    "        x2 = x.copy()\n",
    "        x2[i] -= h\n",
    "        f2 = f_grad(x2)\n",
    "        H[:, i] = (f1 - f2) / (2 * h)\n",
    "    return H\n",
    "\n",
    "# Ponto de teste\n",
    "x0 = np.array([1.0, 1.0])\n",
    "eps = np.sqrt(np.finfo(float).eps)\n",
    "\n",
    "# Avaliação da função\n",
    "f_val, g_analytical, H_analytical = ex02(x0)\n",
    "\n",
    "# Gradiente numérico\n",
    "g_numeric = approx_fprime(x0, lambda x: ex02(x)[0], eps)\n",
    "\n",
    "# Hessiana numérica via gradiente\n",
    "H_numeric = numerical_hessian(lambda x: ex02(x)[1], x0)\n",
    "\n",
    "# Diferenças absolutas\n",
    "grad_diff = np.abs(g_numeric - g_analytical)\n",
    "hess_diff = np.abs(H_numeric - H_analytical)\n",
    "\n",
    "grad_diff, hess_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9887743-47fd-4f38-b515-9b3f3015b207",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min_{x, y} \n",
    "\\Bigl[\n",
    "1 \n",
    "+ (x + y + 1)^2 \\,\\bigl(19 - 14x + 3x^2 - 14y + 6xy + 3y^2\\bigr)\n",
    "\\Bigr]\n",
    "\\;\\times\\;\n",
    "\\Bigl[\n",
    "30 \n",
    "+ (2x - 3y)^2 \\,\\bigl(18 - 32x^2 + 12x^2 + 48y - 36xy + 27y^2\\bigr)\n",
    "\\Bigr]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb4ba81-dd3c-4358-ac4f-0b039762c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função e gradiente analítico\n",
    "def goldstein_price_fg(x):\n",
    "    x1, x2 = x\n",
    "    a = x1 + x2 + 1\n",
    "    b = 2 * x1 - 3 * x2\n",
    "\n",
    "    A = 1 + a**2 * (19 - 14 * x1 + 3 * x1**2 - 14 * x2 + 6 * x1 * x2 + 3 * x2**2)\n",
    "    B = 30 + b**2 * (18 - 32 * x1 + 12 * x1**2 + 48 * x2 - 36 * x1 * x2 + 27 * x2**2)\n",
    "\n",
    "    f = A * B\n",
    "\n",
    "    dA_dx1 = 2 * a * (19 - 14 * x1 + 3 * x1**2 - 14 * x2 + 6 * x1 * x2 + 3 * x2**2) \\\n",
    "             + a**2 * (-14 + 6 * x1 + 6 * x2)\n",
    "    dA_dx2 = 2 * a * (19 - 14 * x1 + 3 * x1**2 - 14 * x2 + 6 * x1 * x2 + 3 * x2**2) \\\n",
    "             + a**2 * (-14 + 6 * x1 + 6 * x2)\n",
    "\n",
    "    dB_dx1 = 4 * b * (18 - 32 * x1 + 12 * x1**2 + 48 * x2 - 36 * x1 * x2 + 27 * x2**2) \\\n",
    "             + b**2 * (-32 + 24 * x1 - 36 * x2)\n",
    "    dB_dx2 = -6 * b * (18 - 32 * x1 + 12 * x1**2 + 48 * x2 - 36 * x1 * x2 + 27 * x2**2) \\\n",
    "             + b**2 * (48 - 36 * x1 + 54 * x2)\n",
    "\n",
    "    df_dx1 = dA_dx1 * B + A * dB_dx1\n",
    "    df_dx2 = dA_dx2 * B + A * dB_dx2\n",
    "    g = np.array([df_dx1, df_dx2])\n",
    "\n",
    "    return f, g\n",
    "\n",
    "# Hessiana numérica com diferenças centrais\n",
    "def numerical_hessian(grad_func, x, h=1e-5):\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        x1 = x.copy()\n",
    "        x2 = x.copy()\n",
    "        x1[i] += h\n",
    "        x2[i] -= h\n",
    "        g1 = grad_func(x1)\n",
    "        g2 = grad_func(x2)\n",
    "        H[:, i] = (g1 - g2) / (2 * h)\n",
    "    return H\n",
    "\n",
    "# Interface principal\n",
    "def ex03(x):\n",
    "    f, g = goldstein_price_fg(x)\n",
    "    H = numerical_hessian(lambda x_: goldstein_price_fg(x_)[1], x)\n",
    "    return f, g, H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0502458-bd82-444d-a43d-98ccb03abafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) = 3.0\n",
      "∇f(x) = [0. 0.]\n",
      "∇²f(x) =\n",
      " [[ 504.0000021  -215.99999929]\n",
      " [-216.00000055  864.00000477]]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([0.0, -1.0])\n",
    "fval, grad, hess = ex03(x0)\n",
    "print(\"f(x) =\", fval)\n",
    "print(\"∇f(x) =\", grad)\n",
    "print(\"∇²f(x) =\\n\", hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd608434-5b23-466d-9961-c0454262172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Example 03 Results ====\n",
      "\n",
      "Method               |        f(x*) |   nfev |   njev |   nhev |  Time (ms) |  Success\n",
      "--------------------------------------------------------------------------------------\n",
      "Nelder-Mead          |   3.0000e+01 |    121 |    N/A |    N/A |      11.10 |     True\n",
      "BFGS                 |   3.0000e+01 |     16 |     16 |    N/A |       3.00 |     True\n",
      "Newton-CG            |   3.0000e+01 |     13 |     13 |      8 |       3.00 |     True\n",
      "trust-ncg            |   3.0000e+01 |     11 |      9 |      8 |       2.39 |     True\n",
      "trust-krylov         |   3.0000e+01 |      7 |      7 |      6 |       6.04 |     True\n",
      "trust-exact          |   3.0000e+01 |      7 |      7 |      7 |       2.00 |     True\n"
     ]
    }
   ],
   "source": [
    "# Initial point\n",
    "x0 = np.array([0.0, 0.0])\n",
    "\n",
    "# List of methods to compare\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\", \"jac\": lambda x: ex03(x)[1]},\n",
    "    \"Newton-CG\": {\"method\": \"Newton-CG\", \"jac\": lambda x: ex03(x)[1], \"hess\": lambda x: ex03(x)[2]},\n",
    "    \"trust-ncg\": {\"method\": \"trust-ncg\", \"jac\": lambda x: ex03(x)[1], \"hess\": lambda x: ex03(x)[2]},\n",
    "    \"trust-krylov\": {\"method\": \"trust-krylov\", \"jac\": lambda x: ex03(x)[1], \"hess\": lambda x: ex03(x)[2]},\n",
    "    \"trust-exact\": {\"method\": \"trust-exact\", \"jac\": lambda x: ex03(x)[1], \"hess\": lambda x: ex03(x)[2]},\n",
    "}\n",
    "\n",
    "# Executa as otimizações e armazena resultados\n",
    "results = {}\n",
    "\n",
    "for name, opts in methods.items():\n",
    "    start_time = time.time()\n",
    "    res = minimize(lambda x: ex03(x)[0], x0, **opts, options={\"disp\": False})\n",
    "    elapsed_time = (time.time() - start_time) * 1000  # em ms\n",
    "    results[name] = {\n",
    "        \"x0\": x0,\n",
    "        \"x*\": res.x,\n",
    "        \"fval\": res.fun,\n",
    "        \"nfev\": res.nfev,\n",
    "        \"njev\": res.get(\"njev\", None),\n",
    "        \"nhev\": res.get(\"nhev\", None),\n",
    "        \"time\": elapsed_time,\n",
    "        \"success\": res.success\n",
    "    }\n",
    "\n",
    "# Apresenta os resultados com alinhamento\n",
    "print(\"\\n==== Example 03 Results ====\\n\")\n",
    "header = f\"{'Method':<20} | {'f(x*)':>12} | {'nfev':>6} | {'njev':>6} | {'nhev':>6} | {'Time (ms)':>10} | {'Success':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for method, data in results.items():\n",
    "    print(f\"{method:<20} | {data['fval']:12.4e} | {data['nfev']:6d} | \"\n",
    "          f\"{data['njev'] if data['njev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['nhev'] if data['nhev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['time']:10.2f} | {str(data['success']):>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf01147-d3dd-4e86-a0de-6c1e7f0e3fdd",
   "metadata": {},
   "source": [
    "Problem Statistics: \n",
    "\n",
    "\\# of continuous variables: 2\n",
    "\n",
    "\\# of known solutions: 4\n",
    "\n",
    "Global solution:\n",
    "\n",
    "Objective function: 3\n",
    "\n",
    "Continuous variables: $x_1 = 0.0; x_2 = -1.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb89aa0-4642-4f14-b218-58a8b248c1f7",
   "metadata": {},
   "source": [
    "$$\n",
    "f_1(x) \\;=\\; -20 \\, e^{-0.2 \\,\\sqrt{\\frac{1}{D}\\,\\sum_{i=1}^{D} x_i^2}} \n",
    "\\;-\\; e^{\\frac{1}{D}\\,\\sum_{i=1}^{D} \\cos\\bigl(2\\pi x_i\\bigr)} \n",
    "\\;+\\; 20 \n",
    "\\;+\\; e\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c4eaac-fdaf-43aa-ab47-0213cb2022fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Valor e gradiente da função Ackley 1\n",
    "def ackley1_fg(x):\n",
    "    D = len(x)\n",
    "    sum_sq = np.sum(x**2)\n",
    "    sum_cos = np.sum(np.cos(2 * np.pi * x))\n",
    "    \n",
    "    term1 = -20 * np.exp(-0.2 * np.sqrt(sum_sq / D))\n",
    "    term2 = -np.exp(sum_cos / D)\n",
    "    f = term1 + term2 + 20 + np.e\n",
    "\n",
    "    # Gradiente analítico\n",
    "    sqrt_sum_sq = np.sqrt(sum_sq / D)\n",
    "    if sqrt_sum_sq == 0:\n",
    "        grad1 = 0\n",
    "    else:\n",
    "        grad1 = (4 * x / (D * sqrt_sum_sq)) * np.exp(-0.2 * sqrt_sum_sq)\n",
    "\n",
    "    grad2 = (2 * np.pi / D) * np.sin(2 * np.pi * x) * np.exp(sum_cos / D)\n",
    "\n",
    "    g = grad1 + grad2\n",
    "    return f, g\n",
    "\n",
    "# Hessiana numérica usando gradiente externo\n",
    "def numerical_hessian(grad_func, x, h=1e-5):\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        x1 = x.copy()\n",
    "        x2 = x.copy()\n",
    "        x1[i] += h\n",
    "        x2[i] -= h\n",
    "        g1 = grad_func(x1)\n",
    "        g2 = grad_func(x2)\n",
    "        H[:, i] = (g1 - g2) / (2 * h)\n",
    "    return H\n",
    "\n",
    "# Interface final\n",
    "def ackley1(x):\n",
    "    f, g = ackley1_fg(x)\n",
    "    H = numerical_hessian(lambda x_: ackley1_fg(x_)[1], x)\n",
    "    return f, g, H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a3cbf68-7e45-4b85-919a-77a7b7962bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) = 4.440892098500626e-16\n",
      "∇f(x) = [0. 0. 0. 0. 0.]\n",
      "∇²f(x) =\n",
      " [[178906.74089307      0.              0.              0.\n",
      "       0.        ]\n",
      " [     0.         178906.74089307      0.              0.\n",
      "       0.        ]\n",
      " [     0.              0.         178906.74089307      0.\n",
      "       0.        ]\n",
      " [     0.              0.              0.         178906.74089307\n",
      "       0.        ]\n",
      " [     0.              0.              0.              0.\n",
      "  178906.74089307]]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(5)\n",
    "fval, grad, hess = ackley1(x0)\n",
    "print(\"f(x) =\", fval)\n",
    "print(\"∇f(x) =\", grad)\n",
    "print(\"∇²f(x) =\\n\", hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9a48c4-921e-42b6-a95e-faa6291cf59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Example 03 Results ====\n",
      "\n",
      "Method               |        f(x*) |   nfev |   njev |   nhev |  Time (ms) |  Success\n",
      "--------------------------------------------------------------------------------------\n",
      "Nelder-Mead          |   3.5745e+00 |    145 |    N/A |    N/A |      35.26 |     True\n",
      "BFGS                 |   3.5745e+00 |      7 |      7 |    N/A |       5.19 |     True\n",
      "Newton-CG            |   3.5745e+00 |      4 |      4 |      3 |       2.92 |     True\n",
      "trust-ncg            |   3.5745e+00 |      3 |      3 |      2 |       2.00 |     True\n",
      "trust-krylov         |   3.5745e+00 |      3 |      3 |      2 |       3.00 |     True\n",
      "trust-exact          |   3.5745e+00 |      3 |      3 |      3 |       4.00 |     True\n"
     ]
    }
   ],
   "source": [
    "# Initial point\n",
    "x0 = np.ones(5)\n",
    "\n",
    "# List of methods to compare\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\", \"jac\": lambda x: ackley1(x)[1]},\n",
    "    \"Newton-CG\": {\"method\": \"Newton-CG\", \"jac\": lambda x: ackley1(x)[1], \"hess\": lambda x: ackley1(x)[2]},\n",
    "    \"trust-ncg\": {\"method\": \"trust-ncg\", \"jac\": lambda x: ackley1(x)[1], \"hess\": lambda x: ackley1(x)[2]},\n",
    "    \"trust-krylov\": {\"method\": \"trust-krylov\", \"jac\": lambda x: ackley1(x)[1], \"hess\": lambda x: ackley1(x)[2]},\n",
    "    \"trust-exact\": {\"method\": \"trust-exact\", \"jac\": lambda x: ackley1(x)[1], \"hess\": lambda x: ackley1(x)[2]},\n",
    "}\n",
    "\n",
    "# Executa as otimizações e armazena resultados\n",
    "results = {}\n",
    "\n",
    "for name, opts in methods.items():\n",
    "    start_time = time.time()\n",
    "    res = minimize(lambda x: ackley1(x)[0], x0, **opts, options={\"disp\": False})\n",
    "    elapsed_time = (time.time() - start_time) * 1000  # em ms\n",
    "    results[name] = {\n",
    "        \"x0\": x0,\n",
    "        \"x*\": res.x,\n",
    "        \"fval\": res.fun,\n",
    "        \"nfev\": res.nfev,\n",
    "        \"njev\": res.get(\"njev\", None),\n",
    "        \"nhev\": res.get(\"nhev\", None),\n",
    "        \"time\": elapsed_time,\n",
    "        \"success\": res.success\n",
    "    }\n",
    "\n",
    "# Apresenta os resultados com alinhamento\n",
    "print(\"\\n==== Example 03 Results ====\\n\")\n",
    "header = f\"{'Method':<20} | {'f(x*)':>12} | {'nfev':>6} | {'njev':>6} | {'nhev':>6} | {'Time (ms)':>10} | {'Success':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for method, data in results.items():\n",
    "    print(f\"{method:<20} | {data['fval']:12.4e} | {data['nfev']:6d} | \"\n",
    "          f\"{data['njev'] if data['njev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['nhev'] if data['nhev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{data['time']:10.2f} | {str(data['success']):>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8a548-21b6-4138-b970-191555307832",
   "metadata": {},
   "source": [
    "## Exercício 1 - Função 105 - Rosenbrock\n",
    "\n",
    "Avaliar para diferentes valores de D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c4535",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\n",
    "f_{105}(\\mathbf{x}) = \\sum_{i=1}^{D-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7ac6b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Resultados - Comparação Multi-Dimensional (Função Rosenbrock) ====\n",
      "\n",
      "Método               |   D |        f(x*) |   nfev |   njev |   nhev | Tempo (ms) |  Sucesso\n",
      "--------------------------------------------------------------------------------------------\n",
      "Nelder-Mead          |   2 |   9.6159e-10 |    152 |    N/A |    N/A |       4.95 |     True\n",
      "BFGS                 |   2 |   1.0522e-17 |     31 |     31 |    N/A |       3.18 |     True\n",
      "Newton-CG            |   2 |   4.7684e-14 |     34 |     34 |     28 |       3.79 |     True\n",
      "trust-ncg            |   2 |   4.3588e-13 |     25 |     23 |     22 |       2.15 |     True\n",
      "trust-krylov         |   2 |   2.8553e-14 |     22 |     22 |     19 |      19.88 |     True\n",
      "trust-exact          |   2 |   6.9387e-12 |      6 |      6 |      6 |       1.23 |     True\n",
      "Nelder-Mead          |   5 |   1.4440e-09 |    968 |    N/A |    N/A |      30.28 |     True\n",
      "BFGS                 |   5 |   7.5502e-15 |     62 |     62 |    N/A |       6.36 |     True\n",
      "Newton-CG            |   5 |   2.7081e-04 |   3454 |   3454 |   3416 |     443.45 |     True\n",
      "trust-ncg            |   5 |   4.9392e-09 |   3438 |   2878 |   2877 |     382.06 |     True\n",
      "trust-krylov         |   5 |   2.7551e-09 |    691 |    691 |    682 |     559.41 |     True\n",
      "trust-exact          |   5 |   3.2877e-09 |    734 |    722 |    734 |     278.40 |     True\n",
      "Nelder-Mead          |  10 |   2.4025e+00 |   2622 |    N/A |    N/A |     113.65 |     True\n",
      "BFGS                 |  10 |   4.3518e-14 |     80 |     80 |    N/A |      12.71 |     True\n",
      "Newton-CG            |  10 |   6.8623e-04 |   4084 |   4084 |   4055 |     651.34 |     True\n",
      "trust-ncg            |  10 |   6.0784e-09 |   3112 |   3047 |   3046 |     482.89 |     True\n",
      "trust-krylov         |  10 |   3.8079e-09 |    783 |    783 |    773 |     848.19 |     True\n",
      "trust-exact          |  10 |   2.8167e-09 |    790 |    781 |    790 |     364.60 |     True\n",
      "Nelder-Mead          |  20 |   6.3276e+01 |   9940 |    N/A |    N/A |     665.31 |     True\n",
      "BFGS                 |  20 |   9.1489e-15 |    172 |    172 |    N/A |      30.33 |     True\n",
      "Newton-CG            |  20 |   1.5572e-03 |   4781 |   4781 |   4735 |    1054.81 |     True\n",
      "trust-ncg            |  20 |   1.4511e-09 |   4048 |   4037 |   4036 |     877.99 |     True\n",
      "trust-krylov         |  20 |   3.1901e-09 |   1252 |   1252 |   1245 |    1049.41 |     True\n",
      "trust-exact          |  20 |   2.8568e-09 |   1023 |   1014 |   1023 |     543.28 |     True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Função de Rosenbrock com gradiente e hessiana\n",
    "def f105_rosenbrock(x):\n",
    "    fval = np.sum(100.0 * (x[1:] - x[:-1]**2)**2 + (x[:-1] - 1)**2)\n",
    "\n",
    "    grad = np.zeros_like(x)\n",
    "    grad[0] = -400 * x[0] * (x[1] - x[0]**2) + 2 * (x[0] - 1)\n",
    "    for i in range(1, len(x)-1):\n",
    "        grad[i] = 200 * (x[i] - x[i-1]**2) - 400 * x[i] * (x[i+1] - x[i]**2) + 2 * (x[i] - 1)\n",
    "    grad[-1] = 200 * (x[-1] - x[-2]**2)\n",
    "\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "    for i in range(n - 1):\n",
    "        H[i, i] += 1200 * x[i]**2 - 400 * x[i+1] + 2\n",
    "        H[i, i+1] += -400 * x[i]\n",
    "        H[i+1, i] += -400 * x[i]\n",
    "    H[-1, -1] += 200\n",
    "\n",
    "    return fval, grad, H\n",
    "\n",
    "# Configurações\n",
    "dimensions = [2, 5, 10, 20]\n",
    "n_runs = 10\n",
    "\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\", \"jac\": lambda x: f105_rosenbrock(x)[1]},\n",
    "    \"Newton-CG\": {\"method\": \"Newton-CG\", \"jac\": lambda x: f105_rosenbrock(x)[1], \"hess\": lambda x: f105_rosenbrock(x)[2]},\n",
    "    \"trust-ncg\": {\"method\": \"trust-ncg\", \"jac\": lambda x: f105_rosenbrock(x)[1], \"hess\": lambda x: f105_rosenbrock(x)[2]},\n",
    "    \"trust-krylov\": {\"method\": \"trust-krylov\", \"jac\": lambda x: f105_rosenbrock(x)[1], \"hess\": lambda x: f105_rosenbrock(x)[2]},\n",
    "    \"trust-exact\": {\"method\": \"trust-exact\", \"jac\": lambda x: f105_rosenbrock(x)[1], \"hess\": lambda x: f105_rosenbrock(x)[2]},\n",
    "}\n",
    "\n",
    "results_all = []\n",
    "\n",
    "# Execução\n",
    "for D in dimensions:\n",
    "    x0 = np.random.uniform(-2, 2, D)\n",
    "\n",
    "    for name, opts in methods.items():\n",
    "        times = []\n",
    "        last_res = None\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            try:\n",
    "                start = time.time()\n",
    "                res = minimize(lambda x: f105_rosenbrock(x)[0], x0, **opts, options={\"maxiter\": 10000, \"disp\": False})\n",
    "                elapsed = (time.time() - start) * 1000\n",
    "                times.append(elapsed)\n",
    "                last_res = res\n",
    "            except Exception as e:\n",
    "                print(f\"[Erro] {name} D={D}: {e}\")\n",
    "                times.append(np.nan)\n",
    "\n",
    "        if last_res is not None:\n",
    "            results_all.append({\n",
    "                \"Método\": name,\n",
    "                \"D\": D,\n",
    "                \"f(x*)\": last_res.fun,\n",
    "                \"nfev\": last_res.nfev,\n",
    "                \"njev\": last_res.get(\"njev\", None),\n",
    "                \"nhev\": last_res.get(\"nhev\", None),\n",
    "                \"Tempo (ms)\": np.nanmean(times),\n",
    "                \"Sucesso\": last_res.success\n",
    "            })\n",
    "\n",
    "# Impressão dos resultados\n",
    "print(\"\\n==== Resultados - Comparação Multi-Dimensional (Função Rosenbrock) ====\\n\")\n",
    "header = f\"{'Método':<20} | {'D':>3} | {'f(x*)':>12} | {'nfev':>6} | {'njev':>6} | {'nhev':>6} | {'Tempo (ms)':>10} | {'Sucesso':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for r in results_all:\n",
    "    print(f\"{r['Método']:<20} | {r['D']:>3} | {r['f(x*)']:12.4e} | {r['nfev']:6d} | \"\n",
    "          f\"{r['njev'] if r['njev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{r['nhev'] if r['nhev'] is not None else '  N/A':>6} | \"\n",
    "          f\"{r['Tempo (ms)']:10.2f} | {str(r['Sucesso']):>8}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c398b-3e9c-46f1-997a-2310acedd79e",
   "metadata": {},
   "source": [
    "## Exercício 2- Função 114 - Scahffer 3\n",
    "\n",
    "Testar para diferentes pontos iniciais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f8df0",
   "metadata": {},
   "source": [
    "$$\n",
    "f_(114)(x_1, x_2) = 0.5 + \n",
    "\\frac{\\cos^2\\left(x_1 \\cdot \\sin(x_2)\\right) - 0.5}\n",
    "{\\left[1 + 0.001\\left(x_1^2 + x_2^2\\right)\\right]^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04af2f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Teste com ponto inicial 1: [-25.09197623  90.14286128] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tikara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:317: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Teste com ponto inicial 2: [46.39878836 19.73169684] ===\n",
      "\n",
      "=== Teste com ponto inicial 3: [-68.79627191 -68.80109593] ===\n",
      "\n",
      "=== Teste com ponto inicial 4: [-88.38327757  73.23522915] ===\n",
      "\n",
      "=== Teste com ponto inicial 5: [20.22300235 41.61451556] ===\n",
      "\n",
      "=== Teste com ponto inicial 6: [-95.88310114  93.98197043] ===\n",
      "\n",
      "=== RESULTADOS DETALHADOS ===\n",
      "========================================================================================================================\n",
      "Ponto Inicial   Método          Tempo Médio     Taxa Sucesso    Média f(x*)     Melhor f(x*)    Melhor Solução            Distância Ótimo\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-25.1, 90.1     Nelder-Mead     4.82            100.0%          0.493726        0.488320        [-23.742175, 70.561294]   73.261958      \n",
      "-25.1, 90.1     BFGS            10.64           100.0%          0.494377        0.494206        [-17.860277, 89.279041]   89.819559      \n",
      "-25.1, 90.1     L-BFGS-B        8.48            100.0%          0.494508        0.494359        [-20.844967, 89.332665]   90.512539      \n",
      "-25.1, 90.1     trust-constr    336.03          100.0%          0.494379        0.494206        [-17.930762, 89.264474]   89.819327      \n",
      "46.4, 19.7      Nelder-Mead     2.25            100.0%          0.444076        0.351146        [20.433494, 20.371597]    27.982924      \n",
      "46.4, 19.7      BFGS            7.66            100.0%          0.375257        0.208781        [5.419944, 16.760282]     16.427052      \n",
      "46.4, 19.7      L-BFGS-B        8.33            100.0%          0.441612        0.426210        [36.117601, 17.265539]    39.507960      \n",
      "46.4, 19.7      trust-constr    195.24          100.0%          0.398609        0.253886        [5.582182, 19.853047]     19.419532      \n",
      "-68.8, -68.8    Nelder-Mead     4.70            100.0%          0.489190        0.482977        [-4.791856, -66.306828]   67.729667      \n",
      "-68.8, -68.8    BFGS            14.30           100.0%          0.487615        0.483895        [-9.660888, -66.922292]   68.856509      \n",
      "-68.8, -68.8    L-BFGS-B        7.09            100.0%          0.492851        0.483895        [-9.661417, -66.922219]   68.856511      \n",
      "-68.8, -68.8    trust-constr    469.84          100.0%          0.488312        0.482977        [4.793018, -66.306744]    67.729666      \n",
      "-88.4, 73.2     Nelder-Mead     4.35            100.0%          0.494375        0.490236        [-26.839278, 73.725423]   77.282484      \n",
      "-88.4, 73.2     BFGS            11.40           100.0%          0.494556        0.486879        [-14.834713, 70.377391]   70.698191      \n",
      "-88.4, 73.2     L-BFGS-B        3.41            100.0%          0.497319        0.496469        [-73.829081, 73.812987]   103.516512     \n",
      "-88.4, 73.2     trust-constr    1048.69         90.0%           0.492126        0.489053        [-5.002439, 75.717136]    74.631862      \n",
      "20.2, 41.6      Nelder-Mead     2.92            100.0%          0.443381        0.435167        [6.556354, 41.641989]     40.917562      \n",
      "20.2, 41.6      BFGS            6.03            100.0%          0.442570        0.425058        [8.776797, 38.806247]     38.565138      \n",
      "20.2, 41.6      L-BFGS-B        7.79            100.0%          0.445357        0.437811        [17.415466, 39.141714]    41.699453      \n",
      "20.2, 41.6      trust-constr    135.22          100.0%          0.441785        0.417897        [-4.017257, 38.099714]    37.064946      \n",
      "-95.9, 94.0     Nelder-Mead     5.08            100.0%          0.496910        0.494967        [-5.372740, 94.544118]    93.445587      \n",
      "-95.9, 94.0     BFGS            18.37           100.0%          0.495453        0.494436        [-8.095984, 91.727232]    90.835625      \n",
      "-95.9, 94.0     L-BFGS-B        4.82            100.0%          0.498231        0.495439        [-29.995655, 92.575782]   96.122676      \n",
      "-95.9, 94.0     trust-constr    4284.09         80.0%           0.495380        0.494321        [-51.862799, 92.642546]   105.079865     \n",
      "\n",
      "=== ANÁLISE POR MÉTODO ===\n",
      "==========================================================================================\n",
      "Método          Média Tempo     Taxa Sucesso    Melhor f(x*)    Distância Média\n",
      "------------------------------------------------------------------------------------------\n",
      "Nelder-Mead     4.02            100.0          % 0.351146        63.436697      \n",
      "BFGS            11.40           100.0          % 0.208781        62.533679      \n",
      "L-BFGS-B        6.65            100.0          % 0.426210        73.369275      \n",
      "trust-constr    1078.18         95.0           % 0.253886        65.624200      \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Função Scalifier f_114\n",
    "\n",
    "def scalifier114(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    numerator = np.cos(x1 * np.sin(x2))**2 - 0.5\n",
    "    denominator = (1 + 0.001 * (x1**2 + x2**2))**2\n",
    "    return 0.5 + numerator / denominator\n",
    "\n",
    "# Configurações\n",
    "dist_opt = lambda x: np.linalg.norm(x - np.array([0, 1.253115]))\n",
    "n_runs = 10\n",
    "bounds = [(-100, 100), (-100, 100)]\n",
    "initial_points = [\n",
    "    np.array([-25.09197623,  90.14286128]),\n",
    "    np.array([46.39878836, 19.73169684]),\n",
    "    np.array([-68.79627191, -68.80109593]),\n",
    "    np.array([-88.38327757,  73.23522915]),\n",
    "    np.array([20.22300235, 41.61451556]),\n",
    "    np.array([-95.88310114,  93.98197043])\n",
    "]\n",
    "\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\"},\n",
    "    \"L-BFGS-B\": {\"method\": \"L-BFGS-B\", \"bounds\": bounds},\n",
    "    \"trust-constr\": {\"method\": \"trust-constr\", \"bounds\": bounds},\n",
    "}\n",
    "\n",
    "# Teste para diferentes pontos iniciais\n",
    "results = []\n",
    "\n",
    "for i, x0 in enumerate(initial_points):\n",
    "    print(f\"\\n=== Teste com ponto inicial {i+1}: {x0} ===\")\n",
    "\n",
    "    for name, opts in methods.items():\n",
    "        times, solutions, func_values, successes = [], [], [], []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            try:\n",
    "                perturbed_x0 = x0 + np.random.normal(0, 0.1, size=2)\n",
    "                start_time = time.time()\n",
    "                res = minimize(scalifier114, perturbed_x0, **opts,\n",
    "                               options={'maxiter': 10000, 'disp': False})\n",
    "                elapsed_time = (time.time() - start_time) * 1000\n",
    "\n",
    "                times.append(elapsed_time)\n",
    "                solutions.append(res.x)\n",
    "                func_values.append(res.fun)\n",
    "                successes.append(res.success)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro no método {name}: {str(e)}\")\n",
    "                times.append(np.nan)\n",
    "                solutions.append(np.array([np.nan, np.nan]))\n",
    "                func_values.append(np.nan)\n",
    "                successes.append(False)\n",
    "\n",
    "        valid_runs = [i for i in range(n_runs) if successes[i]]\n",
    "        if valid_runs:\n",
    "            avg_time = np.mean([times[i] for i in valid_runs])\n",
    "            avg_solution = np.mean([solutions[i] for i in valid_runs], axis=0)\n",
    "            avg_func = np.mean([func_values[i] for i in valid_runs])\n",
    "            best_func = np.min([func_values[i] for i in valid_runs])\n",
    "            best_solution = solutions[np.argmin([func_values[i] for i in valid_runs])]\n",
    "\n",
    "            results.append({\n",
    "                'Initial Point': f\"{x0[0]:.1f}, {x0[1]:.1f}\",\n",
    "                'Method': name,\n",
    "                'Avg Time (ms)': avg_time,\n",
    "                'Success Rate': f\"{len(valid_runs)/n_runs*100:.1f}%\",\n",
    "                'Avg f(x*)': avg_func,\n",
    "                'Best f(x*)': best_func,\n",
    "                'Best Solution': f\"[{best_solution[0]:.6f}, {best_solution[1]:.6f}]\",\n",
    "                'Distance to Optimum': dist_opt(best_solution)\n",
    "            })\n",
    "\n",
    "# Impressão detalhada\n",
    "deprint = lambda x: print(x)\n",
    "deprint(\"\\n=== RESULTADOS DETALHADOS ===\")\n",
    "deprint(\"=\"*120)\n",
    "deprint(\"{:<15} {:<15} {:<15} {:<15} {:<15} {:<15} {:<25} {:<15}\".format(\n",
    "    'Ponto Inicial', 'Método', 'Tempo Médio', 'Taxa Sucesso', 'Média f(x*)', \n",
    "    'Melhor f(x*)', 'Melhor Solução', 'Distância Ótimo'))\n",
    "deprint(\"-\"*120)\n",
    "\n",
    "for res in results:\n",
    "    deprint(\"{:<15} {:<15} {:<15.2f} {:<15} {:<15.6f} {:<15.6f} {:<25} {:<15.6f}\".format(\n",
    "        res['Initial Point'], res['Method'], res['Avg Time (ms)'], res['Success Rate'],\n",
    "        res['Avg f(x*)'], res['Best f(x*)'], res['Best Solution'], res['Distance to Optimum']))\n",
    "\n",
    "# Análise por método\n",
    "deprint(\"\\n=== ANÁLISE POR MÉTODO ===\")\n",
    "deprint(\"=\"*90)\n",
    "deprint(\"{:<15} {:<15} {:<15} {:<15} {:<15}\".format(\n",
    "    'Método', 'Média Tempo', 'Taxa Sucesso', 'Melhor f(x*)', 'Distância Média'))\n",
    "deprint(\"-\"*90)\n",
    "\n",
    "for method in methods.keys():\n",
    "    method_results = [r for r in results if r['Method'] == method]\n",
    "    if method_results:\n",
    "        avg_time = np.mean([r['Avg Time (ms)'] for r in method_results])\n",
    "        avg_success = np.mean([float(r['Success Rate'][:-1]) for r in method_results])\n",
    "        best_f = np.min([r['Best f(x*)'] for r in method_results])\n",
    "        avg_dist = np.mean([r['Distance to Optimum'] for r in method_results])\n",
    "\n",
    "        deprint(\"{:<15} {:<15.2f} {:<15.1f}% {:<15.6f} {:<15.6f}\".format(\n",
    "            method, avg_time, avg_success, best_f, avg_dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289aeee-9a89-4633-b26e-39cd2477e593",
   "metadata": {},
   "source": [
    "## Exercício 3 - Função 142 - Streched V Senoidal Modificada\n",
    "\n",
    "Avaliar para diferentes valores de D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8065d8f-c65e-4b00-869d-f0f42996c04d",
   "metadata": {},
   "source": [
    "$$\n",
    "f142(\\mathbf{x}) = \\sum_{i=1}^{D-1} \n",
    "\\left( 0.5 x_i^2 + 1.5 x_{i+1}^2 \\right)^{0.3} \\cdot \n",
    "\\left[ \\sin^2 \\left( 40 \\cdot \\left| x_i - x_{i+1} \\right|^{0.2} \\right) + 0.05 \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b8c9d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tikara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:317: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\Tikara\\AppData\\Local\\Temp\\ipykernel_29040\\4209431183.py:66: RuntimeWarning: Mean of empty slice\n",
      "  avg_func = np.nanmean(func_vals)\n",
      "c:\\Users\\Tikara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Tikara\\AppData\\Local\\Temp\\ipykernel_29040\\4209431183.py:68: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = np.nanmean(distances)\n",
      "c:\\Users\\Tikara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:317: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Resultados para f142(x) com bounds [-5, 15] ====\n",
      "Method          D     f(x*)                Time (ms)            Success Rate (%)     Distance to Optimum  Bounds    \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nelder-Mead     2     6.9008e-02 ± 4.97e-02 1.8 ± 0.5            70.0                 2.8436e+00           [-5,15]   \n",
      "BFGS            2     1.1284e-01 ± 3.89e-02 2.6 ± 0.7            70.0                 5.3489e+00           [-5,15]   \n",
      "L-BFGS-B        2     1.3149e-01 ± 7.09e-02 3.4 ± 1.6            100.0                6.4295e+00           [-5,15]   \n",
      "trust-constr    2     1.4922e-01 ± 7.62e-02 44.7 ± 15.4          100.0                7.4769e+00           [-5,15]   \n",
      "Nelder-Mead     5     6.8571e-01 ± 9.89e-02 10.7 ± 3.9           40.0                 1.4694e+01           [-5,15]   \n",
      "BFGS            5     5.8045e-01 ± 7.40e-02 7.0 ± 3.4            30.0                 1.5084e+01           [-5,15]   \n",
      "L-BFGS-B        5     6.6153e-01 ± 1.42e-01 8.7 ± 2.2            100.0                1.3727e+01           [-5,15]   \n",
      "trust-constr    5     5.9167e-01 ± 1.75e-01 135.1 ± 35.8         100.0                1.1295e+01           [-5,15]   \n",
      "Nelder-Mead     10    1.6556e+00 ± 1.41e-01 69.7 ± 22.2          40.0                 2.2880e+01           [-5,15]   \n",
      "BFGS            10    nan ± nan            23.0 ± 9.1           0.0                  nan                  [-5,15]   \n",
      "L-BFGS-B        10    1.8793e+00 ± 7.76e-01 31.9 ± 10.1          100.0                2.2769e+01           [-5,15]   \n",
      "trust-constr    10    1.4274e+00 ± 2.57e-01 1966.0 ± 3077.3      90.0                 1.9128e+01           [-5,15]   \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def f142(x):\n",
    "    D = len(x)\n",
    "    fval = 0.0\n",
    "    for i in range(D-1):\n",
    "        term1 = 0.5 * x[i]**2 + 1.5 * x[i+1]**2\n",
    "        term2 = np.sin(40 * abs(x[i] - x[i+1])**0.2)**2 + 0.05\n",
    "        fval += term1**0.3 * term2\n",
    "    return fval\n",
    "\n",
    "# Configurações\n",
    "dimensions = [2, 5, 10]\n",
    "n_runs = 10\n",
    "bounds = [(-5, 15)]  # Novo intervalo\n",
    "\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\"},\n",
    "    \"L-BFGS-B\": {\"method\": \"L-BFGS-B\", \"bounds\": bounds},\n",
    "    \"trust-constr\": {\"method\": \"trust-constr\", \"bounds\": bounds},\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Define uma seed para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "for D in dimensions:\n",
    "    current_bounds = bounds * D\n",
    "    \n",
    "    for name, opts in methods.items():\n",
    "        times = []\n",
    "        func_vals = []\n",
    "        distances = []\n",
    "        successes = 0\n",
    "        \n",
    "        if opts[\"method\"] in [\"L-BFGS-B\", \"trust-constr\"]:\n",
    "            opts[\"bounds\"] = current_bounds\n",
    "        \n",
    "        for _ in range(n_runs):\n",
    "            try:\n",
    "                x0 = np.random.uniform(low=-5, high=15, size=D)  # Novo intervalo\n",
    "                \n",
    "                start_time = time.time()\n",
    "                res = minimize(f142, x0, **opts, options={'maxiter': 5000, 'disp': False})\n",
    "                elapsed_time = (time.time() - start_time) * 1000\n",
    "                \n",
    "                valid = all(-5 <= xi <= 15 for xi in res.x)\n",
    "                \n",
    "                times.append(elapsed_time)\n",
    "                func_vals.append(res.fun if valid else np.nan)\n",
    "                distances.append(np.linalg.norm(res.x) if valid else np.nan)\n",
    "                successes += int(res.success and valid)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro no método {name} (D={D}): {str(e)}\")\n",
    "                times.append(np.nan)\n",
    "                func_vals.append(np.nan)\n",
    "                distances.append(np.nan)\n",
    "        \n",
    "        avg_time = np.nanmean(times)\n",
    "        std_time = np.nanstd(times)\n",
    "        avg_func = np.nanmean(func_vals)\n",
    "        std_func = np.nanstd(func_vals)\n",
    "        avg_dist = np.nanmean(distances)\n",
    "        success_rate = successes/n_runs*100\n",
    "        \n",
    "        all_results.append({\n",
    "            'Method': name,\n",
    "            'D': D,\n",
    "            'f(x*)': f\"{avg_func:.4e} ± {std_func:.2e}\",\n",
    "            'Time (ms)': f\"{avg_time:.1f} ± {std_time:.1f}\",\n",
    "            'Success Rate (%)': success_rate,\n",
    "            'Distance to Optimum': f\"{avg_dist:.4e}\",\n",
    "            'Bounds': \"[-5,15]\"\n",
    "        })\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n==== Resultados para f142(x) com bounds [-5, 15] ====\")\n",
    "print(\"{:<15} {:<5} {:<20} {:<20} {:<20} {:<20} {:<10}\".format(\n",
    "    'Method', 'D', 'f(x*)', 'Time (ms)', 'Success Rate (%)', \n",
    "    'Distance to Optimum', 'Bounds'))\n",
    "print(\"-\"*120)\n",
    "\n",
    "for res in all_results:\n",
    "    print(\"{:<15} {:<5} {:<20} {:<20} {:<20} {:<20} {:<10}\".format(\n",
    "        res['Method'],\n",
    "        res['D'],\n",
    "        res['f(x*)'],\n",
    "        res['Time (ms)'],\n",
    "        f\"{res['Success Rate (%)']:.1f}\",\n",
    "        res['Distance to Optimum'],\n",
    "        res['Bounds']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647247f-618a-4616-aed0-b6b0f13ef3fe",
   "metadata": {},
   "source": [
    "## Exercício 4 - Função 61 - Hansen\n",
    "\n",
    "A partir de diferentes pontos iniciais, encontrar ao menos dois dos mínimos globais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536f823",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "f_{61}(x) = \\left( \\sum_{i=0}^{4} (i+1)\\cos\\left((i+1)x_1 + i\\right) \\right) \\cdot \\left( \\sum_{j=0}^{4} (j+1)\\cos\\left((j+2)x_2 + j\\right) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41e1c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ponto Inicial 1: [-2.  7.] ===\n",
      "\n",
      "=== Ponto Inicial 2: [6. 6.] ===\n",
      "\n",
      "=== Ponto Inicial 3: [-9.  9.] ===\n",
      "\n",
      "=== Ponto Inicial 4: [ 3. -8.] ===\n",
      "\n",
      "=== Ponto Inicial 5: [ 6.01173398 -5.99699512] ===\n",
      "\n",
      "=== Ponto Inicial 6: [-6.65034835 -7.90864319] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tikara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:317: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS ===\n",
      "====================================================================================================\n",
      "Ponto Inicial   Método          Tempo Médio     Melhor f(x*)         Mínimos Únicos\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[-2.0, 7.0]     Nelder-Mead     1.65            -51.923207           [[-1.5172, 7.7586], [-1.5172, 6.7723], [-0.7562, 8.2449], [-0.7562, 7.2637], [-2.2012, 7.2638]]\n",
      "[-2.0, 7.0]     BFGS            2.00            -51.923208           [[-0.7562, 7.2638], [-2.7888, 8.7387], [-2.7888, 7.7586], [-2.2012, 7.2638], [-2.2012, 6.2659], [-3.3758, 9.2242], [-2.2012, 8.2449]]\n",
      "[-2.0, 7.0]     L-BFGS-B        1.48            -63.955689           [[-10.0, 6.7723], [-2.2012, 5.0553], [-2.7888, 5.6806], [-10.0, -10.0], [-1.5172, 7.7586], [-2.2012, 7.2638], [7.4454, -10.0], [-1.5172, 6.7723]]\n",
      "[-2.0, 7.0]     trust-constr    59.34           -155.369336          [[-1.5172, 5.6806], [-2.2012, 6.2659], [-2.7888, 7.7586], [-2.2012, 7.2638], [-1.5172, 6.7723], [-2.7888, 6.7723], [-0.7562, 7.2638]]\n",
      "[6.0, 6.0]      Nelder-Mead     1.40            -204.548189          [[6.2505, 5.6806], [5.527, 7.2638], [6.2504, 6.7723], [6.8621, 6.2659], [5.527, 5.0554]]\n",
      "[6.0, 6.0]      BFGS            2.35            -91.579511           [[6.2504, 4.4528], [7.4454, 6.7723], [6.2504, 5.6806], [6.2504, 7.7586], [5.527, 6.2659], [7.4454, 5.6806], [8.029, 5.0553], [5.527, 7.2638]]\n",
      "[6.0, 6.0]      L-BFGS-B        1.99            -155.369336          [[-0.0327, 7.7586], [4.766, 5.6806], [-10.0, -10.0], [6.2504, 5.6806], [6.862, 6.2659], [-0.7562, 7.2638], [9.7775, 9.7222]]\n",
      "[6.0, 6.0]      trust-constr    63.32           -204.548195          [[7.4454, 6.7723], [5.527, 6.2659], [6.2504, 6.7723], [5.527, 5.0553], [6.862, 5.0553], [6.862, 6.2659], [5.527, 7.2638], [6.2504, 5.6806]]\n",
      "[-9.0, 9.0]     Nelder-Mead     1.45            -23.769752           [[-10.2397, 10.736], [-9.659, 8.2449], [-8.4844, 10.21], [-8.4844, 9.2243], [-9.072, 8.7388], [-9.6591, 9.2242]]\n",
      "[-9.0, 9.0]     BFGS            2.10            -32.601112           [[-9.072, 9.7222], [-7.8004, 8.7387], [-9.659, 8.2449], [-9.072, 7.7586], [-8.4844, 9.2242], [-10.2397, 8.7387], [-9.659, 9.2242], [-6.3159, 14.0418]]\n",
      "[-9.0, 9.0]     L-BFGS-B        2.59            -32.601112           [[-9.072, 8.7387], [4.082, 3.9268], [-1.5172, -10.0], [-7.8004, 8.7387], [-9.659, 10.0], [4.766, -10.0], [-9.072, 9.7222], [-10.0, -1.8304]]\n",
      "[-9.0, 9.0]     trust-constr    62.02           -155.369336          [[-9.659, 9.2242], [-8.4844, 9.2242], [-7.8004, 5.6806], [-8.4844, 7.2638], [-8.4844, 10.0], [-9.659, 8.2449], [-9.072, 9.7222], [-7.8004, 8.7387]]\n",
      "[3.0, -8.0]     Nelder-Mead     1.46            -63.955688           [[2.9073, -8.6396], [2.9073, -7.511], [2.3267, -8.1136], [3.4943, -9.1273], [4.082, -7.511]]\n",
      "[3.0, -8.0]     BFGS            1.92            -63.955689           [[4.082, -8.6395], [2.9073, -7.511], [2.9073, -8.6395], [2.9073, -9.6253], [2.3267, -8.1136], [3.4943, -8.1136], [4.082, -7.511]]\n",
      "[3.0, -8.0]     L-BFGS-B        2.13            -85.060149           [[9.7775, 8.7387], [-10.0, -10.0], [2.9073, -8.6395], [-0.7562, -8.6395], [4.082, -7.511], [2.9073, -7.511], [8.6098, 3.439], [6.2504, -0.6026], [2.3267, -6.8858]]\n",
      "[3.0, -8.0]     trust-constr    66.89           -204.548195          [[2.9073, -7.511], [2.9073, -8.6395], [3.4943, -8.1136], [4.766, -8.1136], [-0.7562, -7.511], [2.3267, -8.1136]]\n",
      "[6.0, -6.0]     Nelder-Mead     1.25            -91.579510           [[6.2504, -5.7941], [6.2504, -6.8858], [5.527, -6.3005], [6.8621, -5.3026], [5.527, -5.3026]]\n",
      "[6.0, -6.0]     BFGS            2.10            -204.548195          [[6.2504, -4.8078], [6.862, -6.3005], [6.2504, -6.8858], [4.766, -8.1136], [5.527, -6.3005], [4.766, -6.8858], [5.527, -7.511], [7.4454, -8.1136], [1.7459, -9.6253]]\n",
      "[6.0, -6.0]     L-BFGS-B        1.90            -91.579511           [[6.862, -6.3005], [-10.0, -10.0], [9.7775, -10.0], [5.527, -6.3005], [5.527, -5.3026], [-10.0, 9.7222], [8.6098, -8.1136]]\n",
      "[6.0, -6.0]     trust-constr    63.34           -91.579511           [[6.862, -5.3026], [6.862, -6.3005], [5.527, -5.3026], [5.527, -6.3005], [6.2504, -6.8858], [7.4454, -6.8858], [5.527, -8.6395]]\n",
      "[-6.7, -7.9]    Nelder-Mead     1.41            -204.548195          [[-7.0394, -7.5111], [-6.316, -8.1136], [-7.0393, -8.6395], [-6.316, -6.8858], [-5.7043, -7.511]]\n",
      "[-6.7, -7.9]    BFGS            2.22            -204.548195          [[-0.0327, 3.439], [-6.3159, -9.1273], [-7.0394, -8.6395], [-5.7043, -9.6253], [-5.7043, -7.511], [-7.0394, -7.511], [-6.3159, -8.1136], [-7.8004, -6.8858]]\n",
      "[-6.7, -7.9]    L-BFGS-B        2.33            -204.548195          [[-9.659, 9.2242], [-10.0, 6.7723], [-6.3159, -8.1136], [-7.0394, -7.511], [-7.0394, -8.6395], [-0.7562, -1.2278], [-6.3159, -6.8858], [-10.0, -10.0], [9.7775, -10.0]]\n",
      "[-6.7, -7.9]    trust-constr    60.97           -204.548195          [[-7.0394, -8.6395], [-6.3159, -9.1273], [-7.0394, -7.511], [-5.7043, -7.511], [-6.3159, -8.1136], [-6.3159, -6.8858], [-7.8004, -8.1136]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def f61(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    sum1 = sum((i+1) * np.cos((i+1)*x1 + i) for i in range(0, 5))\n",
    "    sum2 = sum((j+1) * np.cos((j+2)*x2 + j) for j in range(0, 5))\n",
    "    return sum1 * sum2\n",
    "\n",
    "# Novos pontos iniciais diferentes dos do colega\n",
    "initial_points = [\n",
    "    np.array([-2.0, 7.0]),\n",
    "    np.array([6.0, 6.0]),\n",
    "    np.array([-9.0, 9.0]),\n",
    "    np.array([3.0, -8.0]),\n",
    "    np.random.uniform(-10, 10, 2),\n",
    "    np.random.uniform(-10, 10, 2)\n",
    "]\n",
    "\n",
    "methods = {\n",
    "    \"Nelder-Mead\": {\"method\": \"Nelder-Mead\"},\n",
    "    \"BFGS\": {\"method\": \"BFGS\"},\n",
    "    \"L-BFGS-B\": {\"method\": \"L-BFGS-B\", \"bounds\": [(-10, 10), (-10, 10)]},\n",
    "    \"trust-constr\": {\"method\": \"trust-constr\", \"bounds\": [(-10, 10), (-10, 10)]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "found_minima = []\n",
    "\n",
    "n_runs = 10\n",
    "tolerance = 0.5\n",
    "\n",
    "for idx, x0 in enumerate(initial_points):\n",
    "    print(f\"\\n=== Ponto Inicial {idx+1}: {x0} ===\")\n",
    "    \n",
    "    for method_name, opts in methods.items():\n",
    "        best_solutions = []\n",
    "        times = []\n",
    "        best_values = []\n",
    "        \n",
    "        for _ in range(n_runs):\n",
    "            perturbed_x0 = x0 + np.random.normal(0, 0.5, size=2)\n",
    "            \n",
    "            start = time.time()\n",
    "            res = minimize(f61, perturbed_x0, **opts, options={'maxiter': 5000, 'disp': False})\n",
    "            duration = (time.time() - start) * 1000\n",
    "            \n",
    "            if res.success:\n",
    "                sol = np.round(res.x, decimals=4)\n",
    "                times.append(duration)\n",
    "                best_values.append(res.fun)\n",
    "                best_solutions.append(sol.tolist())\n",
    "        \n",
    "        unique_minima = []\n",
    "        for sol in best_solutions:\n",
    "            if not any(np.linalg.norm(np.array(sol) - np.array(existing)) < tolerance for existing in unique_minima):\n",
    "                unique_minima.append(sol)\n",
    "        \n",
    "        if unique_minima:\n",
    "            results.append({\n",
    "                'Initial Point': x0,\n",
    "                'Method': method_name,\n",
    "                'Avg Time (ms)': np.mean(times),\n",
    "                'Best f(x*)': np.min(best_values),\n",
    "                'Unique Minima Found': unique_minima\n",
    "            })\n",
    "\n",
    "print(\"\\n=== RESULTADOS ===\")\n",
    "print(\"=\"*100)\n",
    "print(\"{:<15} {:<15} {:<15} {:<20} {}\".format(\"Ponto Inicial\", \"Método\", \"Tempo Médio\", \"Melhor f(x*)\", \"Mínimos Únicos\"))\n",
    "print(\"-\"*100)\n",
    "\n",
    "for res in results:\n",
    "    print(\"{:<15} {:<15} {:<15.2f} {:<20.6f} {}\".format(\n",
    "        f\"[{res['Initial Point'][0]:.1f}, {res['Initial Point'][1]:.1f}]\",\n",
    "        res['Method'],\n",
    "        res['Avg Time (ms)'],\n",
    "        res['Best f(x*)'],\n",
    "        res['Unique Minima Found']\n",
    "    ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
